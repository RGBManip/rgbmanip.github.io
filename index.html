<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RGBManip: Monocular Image-based Robotic Manipulation through Active Object Pose Estimation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/rgb.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/RGBManip">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
      <!-- <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div> -->
      </div>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">RGBManip: Monocular Image-based Robotic Manipulation through Active Object Pose Estimation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://boshi-an.github.io/">Boshi An*<sup>1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://gengyiran.github.io/">Yiran Geng*<sup>1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://ck-kai.github.io/">Kai Chen*<sup>3</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://clorislili.github.io/clorisLi/">Xiaoqi Li<sup>1,2</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://www.cse.cuhk.edu.hk/~qdou/">Qi Dou<sup>3</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://zsdonghao.github.io/">Hao Dong<sup>1</sup></a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of CS, Peking University and National Key Laboratory for Multimedia Information Processing</span>
            <span class="author-block"><sup>2</sup>Beijing Academy of Artificial Intelligence (BAAI)</span>
            <span class="author-block"><sup>3</sup>Department of Computer Science and Engineering, Chinese University of Hong Kong</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" alt="Teaser" width="100%">
      <h2 class="subtitle has-text-centered">
        An eye-on-hand camera captures multiple RGB images to estimate
        the object pose in the manipulation process.      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/sim1.webm"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/sim2.webm"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/sim3.webm"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/sim4.webm"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Impedance_demo.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Door.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Drawer.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Mug.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Pot.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Robotic manipulation requires accurate perception of the 
          environment, which poses a significant challenge
          due to its inherent complexity and constantly changing nature.
          In this context, RGB image and point-cloud observations
          are two commonly used modalities in visual-based robotic
          manipulation, but each of these modalities have their own
          limitations. Commercial point-cloud observations often suffer
          from issues like sparse sampling and noisy output due to
          the limits of the emission-reception imaging principle. On the
          other hand, RGB images, while rich in texture information,
          lack essential depth and 3D information crucial for robotic
          manipulation. To mitigate these challenges, we propose an
          image-only robotic manipulation framework that leverages
          an eye-on-hand monocular camera installed on the robotâ€™s
          parallel gripper. By moving with the robot gripper, this camera
          gains the ability to actively perceive object from multiple
          perspectives during the manipulation process. This enables
          the estimation of 6D object poses, which can be utilized for
          manipulation. While, obtaining images from more and diverse
          viewpoints typically improves pose estimation, it also increases
          the manipulation time. To address this trade-off, we employ a
          reinforcement learning policy to synchronize the manipulation
          strategy with active perception, achieving a balance between 6D
          pose accuracy and manipulation efficiency. Our experimental
          results in both simulated and real-world environments showcase
          the state-of-the-art effectiveness of our approach. We believe
          that our method will inspire further research on real-world-oriented 
          robotic manipulation.
        </div>
      </div>
    </div>
  </div>
  <br>
  <br>
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <!-- <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div> -->
        <div class="content has-text-centered">
          <video id="replay-video"
                controls
                muted
                preload
                playsinline
                width="75%">
            <source src="./static/videos/rgbmanip_main.mp4"
                    type="video/mp4">
          </video>
        </div>
        </div>
      </div>
    </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2310.03478">
        <i class="fas fa-file-pdf"></i>
      </a>
     
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Template is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>

      
    </div>
  </div>
</footer>

</body>
</html>